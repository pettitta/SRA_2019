summary(model_category)
plot_model(model_category)
plot_model(model_category)
plotluck::plotluck(daily_text_pronouns, daily_zscore ~ fpp_categary)
plotluck::plotluck(daily_text_pronouns, daily_zscore ~ fpp_categary)
plotluck::plotluck(daily_text_pronouns, daily_category ~ fpp_categary)
daily_text_pronouns$fpp_categary <- factor(ifelse(daily_text_pronouns$fpp_zscore >= 2, "high","low"))
model_category <- lmer(daily_zscore ~ fpp_categary + (1|participant_id),daily_text_pronouns,REML=FALSE)
summary(model_category)
plot_model(model_category)
plotluck::plotluck(daily_text_pronouns, daily_category ~ fpp_categary)
plotluck::plotluck(daily_text_pronouns, daily_zscore ~ fpp_categary)
plotluck::plotluck(daily_text_pronouns, daily_zscore ~ fpp_categary,plot.points=TRUE)
plotluck::plotluck(daily_text_pronouns, daily_zscore ~ fpp_categary,geom="box")
plotluck::plotluck(daily_text_pronouns, daily_zscore ~ fpp_categary,opts=plotluck.options(geom="box"))
plot_model(model_category)
daily_text_pronouns$fpp_categary <- factor(ifelse(daily_text_pronouns$fpp_zscore >= 1, "high","low"))
model_category <- lmer(daily_zscore ~ fpp_categary + (1|participant_id),daily_text_pronouns,REML=FALSE)
summary(model_category)
plot_model(model_category)
plotluck::plotluck(daily_text_pronouns, daily_zscore ~ fpp_categary,opts=plotluck.options(geom="box"))
daily_text_pronouns$fpp_categary <- factor(ifelse(daily_text_pronouns$fpp_zscore >= 2, "high","low"))
model_category <- lmer(daily_zscore ~ fpp_categary + (1|participant_id),daily_text_pronouns,REML=FALSE)
summary(model_category)
plot_model(model_category)
plotluck::plotluck(daily_text_pronouns, daily_zscore ~ fpp_categary,opts=plotluck.options(geom="box"))
daily_text_pronouns$daily_category <- factor(ifelse(daily_text_pronouns$daily_zscore <= -2, "low","high"))
daily_text_pronouns$fpp_categary <- factor(ifelse(daily_text_pronouns$fpp_zscore >= 2, "high","low"))
model_category <- lmer(daily_zscore ~ fpp_categary + (1|participant_id),daily_text_pronouns,REML=FALSE)
summary(model_category)
plot_model(model_category)
plotluck::plotluck(daily_text_pronouns, daily_zscore ~ fpp_categary,opts=plotluck.options(geom="box"))
plotluck::plotluck(daily_text_pronouns, daily_category ~ fpp_categary,opts=plotluck.options(geom="box"))
plotluck::plotluck(daily_text_pronouns, daily_category ~ fpp_categary)
daily_text_pronouns$daily_category <- factor(ifelse(daily_text_pronouns$daily_zscore <= -1, "low","high"))
daily_text_pronouns$fpp_categary <- factor(ifelse(daily_text_pronouns$fpp_zscore >= 2, "high","low"))
model_category <- lmer(daily_zscore ~ fpp_categary + (1|participant_id),daily_text_pronouns,REML=FALSE)
summary(model_category)
plot_model(model_category)
plotluck::plotluck(daily_text_pronouns, daily_category ~ fpp_categary)
opts <- plotluck.options(verbose=TRUE)
plotluck::plotluck(daily_text_pronouns, daily_category ~ fpp_categary, opts=opts)
plotluck::plotluck(daily_text_pronouns, daily_zscore ~ fpp_categary, opts=opts)
plotluck::plotluck(daily_text_pronouns, daily_zscore ~ fpp_zscore, opts=opts)
plotluck::plotluck(daily_text_pronouns, daily_zscore ~ fpp_zscore|participant_id, opts=opts)
plotluck::plotluck(daily_text_pronouns, daily_zscore ~ fpp_zscore|fpp_categary, opts=opts)
daily_text_pronouns$fpp_categary <- factor(ifelse(daily_text_pronouns$fpp_zscore >= 1, "high","low"))
plotluck::plotluck(daily_text_pronouns, daily_zscore ~ fpp_zscore|fpp_categary, opts=opts)
plotluck::plotluck(daily_text_pronouns, daily_zscore ~ fpp_zscore|daily_category, opts=opts)
daily_text_pronouns$daily_category <- factor(ifelse(daily_text_pronouns$daily_zscore <= 0, "low","high"))
daily_text_pronouns$fpp_categary <- factor(ifelse(daily_text_pronouns$fpp_zscore >= 1, "high","low"))
model_category <- lmer(daily_zscore ~ fpp_categary + (1|participant_id),daily_text_pronouns,REML=FALSE)
summary(model_category)
plot_model(model_category)
plot_model(model_category)
opts <- plotluck.options(verbose=TRUE)
plotluck::plotluck(daily_text_pronouns, daily_zscore ~ fpp_zscore|daily_category, opts=opts)
hist(daily_text_pronouns$daily_sentiment_zscore)
daily_text_pronouns$sentiment_category <- factor(ifelse(daily_text_pronouns$fpp_zscore <= -1, "low","high"))
plotluck::plotluck(daily_text_pronouns, daily_zscore ~ fpp_zscore|sentiment_category, opts=opts)
daily_text_pronouns$sentiment_category <- factor(ifelse(daily_text_pronouns$daily_sentiment_zscore <= -1, "low","high"))
plotluck::plotluck(daily_text_pronouns, daily_zscore ~ fpp_zscore|sentiment_category, opts=opts)
daily_text_pronouns$sentiment_category <- factor(ifelse(daily_text_pronouns$daily_sentiment_zscore <= -0, "low","high"))
plotluck::plotluck(daily_text_pronouns, daily_zscore ~ fpp_zscore|sentiment_category, opts=opts)
hist(daily_text_pronouns$n_zscore)
plotluck::plotluck(daily_text_pronouns, daily_zscore ~ n_zscore|sentiment_category, opts=opts)
plotluck::plotluck(daily_text_pronouns, daily_zscore ~ n_zscore|fpp_category, opts=opts)
plotluck::plotluck(daily_text_pronouns, daily_zscore ~ n_zscore|fpp_categary, opts=opts)
daily_text_pronouns$fpp_category <- factor(ifelse(daily_text_pronouns$fpp_zscore >= 1, "high","low"))
plotluck::plotluck(daily_text_pronouns, daily_zscore ~ n_zscore|fpp_category, opts=opts)
model_category <- lmer(n_zscore ~ fpp_category + (1|participant_id),daily_text_pronouns,REML=FALSE)
summary(model_category)
plot_model(model_category)
plotluck::plotluck(daily_text_pronouns, daily_zscore ~ n_zscore|fpp_category, opts=opts)
plotluck::plotluck(daily_text_pronouns, fpp_category ~ n_zscore, opts=opts)
plotluck::plotluck(daily_text_pronouns, fpp_zscore ~ n_zscore, opts=opts)
summary(lmer(fpp_zscore ~ n_zscore + (1|participant_id),data=daily_text_pronouns)
summary(lmer(fpp_zscore ~ n_zscore + (1|participant_id),data=daily_text_pronouns)
test <- lmer(fpp_zscore ~ n_zscore + (1|participant_id),data=daily_text_pronouns)
summary(test)
plotluck::plotluck(daily_text_pronouns, fpp_zscore ~ n_zscore, opts=opts)
test <- lmer(fpp_n ~ n + (1|participant_id),data=daily_text_pronouns)
plotluck::plotluck(daily_text_pronouns, fpp_n ~ n, opts=opts)
corr(fpp_zscore ~ n_zscore, daily_text_pronouns)
cor(fpp_zscore ~ n_zscore, daily_text_pronouns)
cor(daily_text_pronouns$fpp_zscore ~ daily_text_pronouns$n_zscore)
cor(daily_text_pronouns$fpp_zscore ~ daily_text_pronouns$n_zscore)
cor(daily_text_pronouns$fpp_zscore, daily_text_pronouns$n_zscore)
plotluck::plotluck(daily_text_pronouns, fpp_zscore ~ n_zscore, opts=opts)
hist(daily_text_pronouns$fpp_zscore)
hist(daily_text_pronouns$fpp_n)
hist(daily_text_pronouns$fpp_zscore)
plot(hmm_2)
hmm <- lmer(daily ~ n_zscore + (1|participant_id), data =daily_text_pronouns,REML=FALSE)
hmm_1 <- lmer(daily ~ fpp_zscore + (1|participant_id), data =daily_text_pronouns,REML=FALSE)
hmm_2 <- lmer(daily ~ fpp_zscore*n_zscore*daily_sentiment_zscore*imean.fpp_n.c + (1|participant_id), data =daily_text_pronouns,REML=FALSE)
plot(hmm_2)
plot(hmm_1)
plot(hmm_2)
plot(hmm)
plot(hmm_1)
plot(hmm_3)
hmm_3 <- lmer(daily ~  fpp_zscore*daily_sentiment_zscore*n_zscore*imean.fpp_n.c*imean.n.c*imean.daily_sentiment +  (1|participant_id), data=daily_text_pronouns,REML=FALSE)
plot(hmm_3)
plot(hmm_1)
hmm_1 <- lmer(daily ~ fpp_zscore*daily_sentiment_zscore + (1|participant_id), data =daily_text_pronouns,REML=FALSE)
plot(hmm_1)
hmm_1 <- lmer(daily ~ fpp_zscore + (1|participant_id), data =daily_text_pronouns,REML=FALSE)
plot(hmm_1)
hmm_1 <- lmer(daily ~ 1 + (1|participant_id), data =daily_text_pronouns,REML=FALSE)
plot(hmm_1)
hmm_1 <- lmer(daily ~ fpp_zscore + (1|participant_id), data =daily_text_pronouns,REML=FALSE)
plot(hmm_1)
qqplot(hmm_1)
plot(hmm_1)
qqnorm(resid(hmm_1))
hmm <- lmer(daily ~ n_zscore*daily_sentiment_zscore + (1|participant_id), data =daily_text_pronouns,REML=FALSE)
hmm_1 <- lmer(daily ~ fpp_zscore*daily_sentiment_zscore + (1|participant_id), data =daily_text_pronouns,REML=FALSE)
qqnorm(resid(hmm_1))
hmm_1 <- lmer(daily ~ fpp_zscore + (1|participant_id), data =daily_text_pronouns,REML=FALSE)
qqnorm(resid(hmm_1))
qqline
qqline()
qqnorm(resid(hmm_1))
qqline()
qqline(resid(hmm_1))
qqline(plot)
qqline(resid(hmm_1))
qqnorm(resid(hmm_1))
qqline(resid(hmm_1))
qqnorm(resid(hmm_1)); qqline(resid(hmm_1))
qqnorm(resid(hmm_1)); qqline(resid(hmm_1))
plot_model(hmm_1, type="re",terms=c("n_zscore","fpp_zscore","daily_sentiment_zscore"),show_values=TRUE)
qqmath(hmm_1)
plot(hmm_1,participant_id ~ resid)
plot(hmm_1,participant_id ~ resid(.,scaled=TRUE))
tab_model(hmm_2,show.std=TRUE)
ggplot(maybe,aes(x=x,y=predicted,color=group)) +
stat_smooth(method = "lm", se = TRUE, fullrange = TRUE)
plot(hmm_1,participant_id ~ resid(.,scaled=TRUE))
REplot <- function(out) {
plotREsim(REsim(out),facet=FALSE)  +
ggtitle('Plot of Random Effects', subtitle = 'Interval Estimates')
}
REplot(hmm_1)
REplot(hmm_1)
REplot <- function(out) {
merTools::plotREsim(merTools::REsim(out),facet=FALSE)  +
ggtitle('Plot of Random Effects', subtitle = 'Interval Estimates')
}
REplot(hmm_1)
library(merTools)
REplot <- function(out) {
plotREsim(REsim(out),facet=FALSE)  +
ggtitle('Plot of Random Effects', subtitle = 'Interval Estimates')
}
REplot(hmm_1)
hmm_1 <- lmer(daily ~ fpp_zscore + (1|participant_id), data =daily_text_pronouns,REML=FALSE)
REplot <- function(out) {
plotREsim(REsim(out),facet=FALSE)  +
ggtitle('Plot of Random Effects', subtitle = 'Interval Estimates')
}
REplot(hmm_1)
REsim(hmm_2)
REsim(hmm_1)
detach("package:lmerTest", unload = TRUE)
hmm_1 <- lmer(daily ~ fpp_zscore + (1|participant_id), data =daily_text_pronouns,REML=FALSE)
REplot <- function(out) {
plotREsim(REsim(out),facet=FALSE)  +
ggtitle('Plot of Random Effects', subtitle = 'Interval Estimates')
}
REsim(hmm_1)
REplot(hmm_1)
hmm_2 <- lmer(daily ~ fpp_zscore*daily_sentiment_zscore*imean.fpp_n.c + (1|participant_id), data =daily_text_pronouns,REML=FALSE)
FEplot <- function(out) {
feEx <- FEsim(out, 1000)
library(ggplot2)
ggplot(feEx[feEx$term!= "(Intercept)", ]) +
aes(x = term, ymin = median - 1.96 * sd,
ymax = median + 1.96 * sd, y = median) +
geom_pointrange() +
geom_hline(yintercept = 0, size = I(1.1), color = I("red")) +
coord_flip() +
theme_bw() + labs(title = "Coefficient Plot of Model",
x = "Median Effect Estimate", y = paste(out@call$formula[[2]]))
}
FEplot(hmm_2)
plot_model(hmm_2)
FEplot(hmm_2)
plot_model(hmm_2,type="std")
plot_model(hmm_2,type="std2")
plot_model(hmm_2,type="std")
plot_model(hmm_2,type="std2")
confint(hmm_2)
visibly::plot_coefficients(hmm_2, ranef=TRUE,which_ranef='participant_id')
FElmer <- function(out) {
coef(summary(out)) %>%
knitr::kable(digits=3) %>%
kableExtra::kable_styling()
}
FElmer(hmm_2)
plotluck::plotluck(daily_text_pronouns, fpp_zscore ~ n_zscore, opts=opts)
rm(list=ls())
packages <- c("rio","tidyverse","reshape","lme4","interactions","jtools","lmerTest","Amelia","mice","lavaan","semTools","janitor","stargazer","plotluck","splitstackshape","gratia","mgcv","Amelia","lubridate","here","fuzzyjoin","Metrics","readxl","tidytext","sjPlot","sjmisc","data.table","sjPlot")
if (length(setdiff(packages, rownames(installed.packages()))) > 0) {
install.packages(setdiff(packages, rownames(installed.packages())))
}
lapply(packages, library, character.only = TRUE)
apatheme=theme_bw()+
theme(panel.grid.major=element_blank(),
panel.grid.minor=element_blank(),
panel.border=element_blank(),
axis.line=element_line(),
text=element_text(family='Helvetica'),
plot.title = element_text(hjust = 0.5))
#raw_text_data <- import(here("data/text_df_unique.csv"))
intensive_ema_data <- import(here("data/ema_df.csv"))
#daily_ema_data <- import(here("data/daily_df.csv"))
raw_text_data <- read_excel(here("data/maps_text_unique_nopw.xlsx"))
daily_ema_data <- import(here("data/maps_daily_20190910.csv"))
#as.POSIXlt(raw_text_data$timestamp_est, format="%m/%d/%Y %H:%M",tz="America/New_York")
# Missing some participant IDs so I'm moving the bucket device ID over to the NA
raw_text_data$participant_id[is.na(raw_text_data$participant_id)] <- raw_text_data$bucket_device_id[is.na(raw_text_data$participant_id)]
stuff_to_remove <- c("Send a chat","Enter message","Say something in pizza_suplex's chat","Search or type web address","Search or enter URL","Type a message","Search YouTube","Say your thing","Write a message","Shantii.thedubb","Type search keywords")
# Remove "send a chat" from thing
raw_text_data <- raw_text_data[!grepl(stuff_to_remove, raw_text_data$text),]
more_stuff_to_remove <- c("w\x95","\x95\x95\x95\x95\x95\x95\x95i\x95","Type a message\x85")
for(i in 1:10){
raw_text_data <- raw_text_data %>% filter(!str_detect(text, more_stuff_to_remove))
}
testing_buckets <- unique(raw_text_data$bucket_device_id)
device_id <- data.frame(matrix(ncol = 2, nrow = 0))
colnames(device_id) <- c("bucket_device_id","participant_id")
for(i in 1:length(testing_buckets)){
what <- unique(raw_text_data$participant_id[raw_text_data$bucket_device_id==testing_buckets[i]])
device_id[i,1] <- testing_buckets[i]
device_id[i,2] <- what
}
# Remove the test data from the dataset
daily_ema_data<-daily_ema_data[!(daily_ema_data$participant_id=="test"),]
intensive_ema_data <- merge(intensive_ema_data,device_id,by="bucket_device_id")
raw_text_data <- raw_text_data %>%
mutate(text = str_replace(text, "ðŸ",""))
# Let's keep only the social media texts
classify <- c("com.atebits.Tweetie2" = "community","com.reddit.Reddit"= "community","com.facebook.Facebook"= "community","com.burbn.instagram"= "community","com.facebook.katana"= "community","com.tumblr"= "community","tv.twitch.android.app"= "community","com.instagram.android"= "community","com.twitter.android"= "community","com.grindrguy.grindrx"= "private","com.Popshow.YOLO"= "private","net.whatsapp.WhatsApp"= "private","com.moxco.bumble"= "private","com.groupme.iphone-app.sharing-ext"= "private","com.apple.MailCompositionService"= "private","com.cardify.tinder"= "private","com.apple.mobilesms.compose"= "private","com.facebook.Messenger"= "private","com.apple.MobileSMS.MessagesNotificationExtension"= "private","com.apple.mobilemail"= "private","com.toyopagroup.picaboo"= "private","com.apple.MobileSMS"= "private","com.samsung.android.messaging"= "private","com.discord"= "private","com.snapchat.android"= "private","com.whatsapp"= "private","com.lipsisoftware.lipsi"= "private")
dating <- c("com.atebits.Tweetie2" = "no","com.reddit.Reddit"= "no","com.facebook.Facebook"= "no","com.burbn.instagram"= "no","com.facebook.katana"= "no","com.tumblr"= "no","tv.twitch.android.app"= "no","com.instagram.android"= "no","com.twitter.android"= "no","com.grindrguy.grindrx"= "yes","com.Popshow.YOLO"= "no","net.whatsapp.WhatsApp"= "no","com.moxco.bumble"= "yes","com.groupme.iphone-app.sharing-ext"= "no","com.apple.MailCompositionService"= "no","com.cardify.tinder"= "yes","com.apple.mobilesms.compose"= "no","com.facebook.Messenger"= "no","com.apple.MobileSMS.MessagesNotificationExtension"= "no","com.apple.mobilemail"= "no","com.toyopagroup.picaboo"= "no","com.apple.MobileSMS"= "no","com.samsung.android.messaging"= "no","com.discord"= "no","com.snapchat.android"= "no","com.whatsapp"= "no","com.lipsisoftware.lipsi"= "no")
social_media <-c("com.atebits.Tweetie2","com.reddit.Reddit","com.facebook.Facebook","com.burbn.instagram","com.facebook.katana","com.tumblr","tv.twitch.android.app","com.instagram.android","com.twitter.android","com.grindrguy.grindrx","com.Popshow.YOLO","net.whatsapp.WhatsApp","com.moxco.bumble","com.groupme.iphone-app.sharing-ext","com.apple.MailCompositionService","com.cardify.tinder","com.apple.mobilesms.compose","com.facebook.Messenger","com.apple.MobileSMS.MessagesNotificationExtension","com.apple.mobilemail","com.toyopagroup.picaboo","com.apple.MobileSMS","com.samsung.android.messaging","com.discord","com.snapchat.android","com.whatsapp","com.lipsisoftware.lipsi")
raw_text_data <- raw_text_data[ raw_text_data$app %in% social_media, ]
raw_text_data$date <- as.Date(raw_text_data$date, format = "%m/%d/%Y")
# First we're going to just check out and see how many messages each participant sent
text_counts <- raw_text_data %>%
group_by(participant_id,date) %>%
tally()
# Now let's see what the first EMA time and date is for each participant
daily_ema_data$bucket_device_id <- daily_ema_data$device_id
daily_ema_data <- daily_ema_data[!is.na(daily_ema_data$participant_id) & !is.na(daily_ema_data$bucket_device_id),]
daily_ema_data$participant_id[is.na(daily_ema_data$participant_id)] <- daily_ema_data$bucket_device_id[is.na(daily_ema_data$participant_id)]
daily_testing_buckets <- unique(daily_ema_data$bucket_device_id)
daily_device_id <- data.frame(matrix(ncol = 2, nrow = 0))
colnames(daily_device_id) <- c("bucket_device_id","participant_id")
for(i in 1:length(daily_testing_buckets)){
what <- unique(daily_ema_data$participant_id[daily_ema_data$bucket_device_id==daily_testing_buckets[i]])
daily_device_id[i,1] <- daily_testing_buckets[i]
daily_device_id[i,2] <- what
}
str(daily_ema_data$time_completed)
as_datetime(as.numeric(daily_ema_data[["time_completed"]])/1000, tz="America/New_York")
daily_ema_data$timestamp_est <- as_datetime(as.numeric(daily_ema_data[["time_completed"]])/1000, tz="America/New_York")
daily_ema_data$date <- as_date(daily_ema_data$timestamp_est)
daily_ema_data$daily <- daily_ema_data$int_answer
daily_ema_data <- daily_ema_data %>%
filter(date > "1969-12-31")
daily_ema_data %>%
ggplot(aes(x = timestamp_est, y = daily, group = participant_id)) +
stat_summary(aes(group = participant_id,color=participant_id), geom = "line", fun.y = mean, size = .5) +
facet_wrap(~participant_id) +
theme(legend.position = "none")
text_counts$date <- as.Date(text_counts$date, format = "%Y-%m-%d")
library(tidytext)
library(dplyr)
text_tidy_data <- raw_text_data
text_tidy_data <- text_tidy_data %>%
dplyr::group_by(participant_id) %>%
dplyr::mutate(textnumber = row_number()) %>%
dplyr::ungroup() %>%
unnest_tokens(word, text)
texting_sentiment <- text_tidy_data %>%
inner_join(get_sentiments("bing")) %>%
count(participant_id, timestamp_est, sentiment) %>%
spread(sentiment, n, fill = 0) %>%
mutate(sentiment = positive - negative)
text_tidy_data_filtered <- text_tidy_data %>%
left_join(texting_sentiment,by = c("participant_id","timestamp_est"))
text_tidy_data_filtered$sentiment[is.na(text_tidy_data_filtered$sentiment)] <- 0
daily_text_sentiment <- text_tidy_data_filtered %>%
group_by(participant_id,date,app) %>%
count(daily_sentiment=mean(sentiment))
daily_text_sentiment$social<- classify[daily_text_sentiment$app]
daily_text_sentiment$dating<- dating[daily_text_sentiment$app]
daily_text_sentiment$social <- as.factor(daily_text_sentiment$social)
daily_text_sentiment$date <- as.Date(daily_text_sentiment$date, format = "%Y-%m-%d")
library(dplyr)
daily_text_sentiment <- daily_text_sentiment %>%
group_by(participant_id, date) %>%
mutate(daily_sentiment = weighted.mean(daily_sentiment, n)) %>%
distinct(participant_id,date,social,.keep_all = TRUE)
hlm_data_sentiment <- merge(daily_text_sentiment, daily_ema_data, by=c("participant_id","date")) %>%
select(participant_id,date,daily_sentiment,n,daily,social,dating,timestamp_ema=timestamp_est)
hlm_data_sentiment$log_n <- log(hlm_data_sentiment$n)
bleh <- hlm_data_sentiment %>%
select(participant_id,timestamp_ema,social,daily,n)
huh <- hlm_data_sentiment %>%
select(participant_id,timestamp_ema,social,daily,n) %>%
tidyr::complete(nesting(participant_id,timestamp_ema),social, fill = list(n = 0))
hlm_data_sentiment <- huh %>%
group_by(participant_id,timestamp_ema) %>%
mutate(daily = ifelse(is.na(daily) & row_number()==1,
replace(daily, 1, mean(daily, na.rm = TRUE)),
daily)) %>%
fill(daily)
hlm_data_sentiment <- hlm_data_sentiment %>%
drop_na(social)
daily.imeans <- plyr::ddply(hlm_data_sentiment, c("participant_id","social"), summarize,imean.n=mean(n, na.rm=TRUE))
daily.imeans$imean.n.c <- scale(daily.imeans$imean.n,center=TRUE,scale=FALSE)
hlm_data_sentiment <- merge(hlm_data_sentiment,daily.imeans,by=c("participant_id","social"))
hlm_data_sentiment$n.state <- hlm_data_sentiment$n - hlm_data_sentiment$imean.n
hlm_data_sentiment$n_zscore <- ave(hlm_data_sentiment$n.state, hlm_data_sentiment$participant_id,hlm_data_sentiment$social, FUN=scale)
hlm_data_sentiment$n_zscore[hlm_data_sentiment$n_zscore=="NaN"] <- 0
community_data <- hlm_data_sentiment %>%
filter(social=="community")
private_data <- hlm_data_sentiment %>%
filter(social=="private")
model_community <- lmer(daily ~ n_zscore + (1|participant_id), data=community_data)
summary(model_community)
sjstats::std_beta(model_community)
model_private <- lmer(daily ~ n_zscore + (1|participant_id), data=private_data)
summary(model_private)
sjstats::std_beta(model_private)
daily_ema_data$timestamp_ema <- daily_ema_data$timestamp_est
daily_ema_data$start_time_ema <- daily_ema_data$timestamp_ema - hours(24)
setDT(text_tidy_data_filtered)
setDT(daily_ema_data)
setDT(text_tidy_data_filtered)[, `:=`(
time1 = timestamp_est,
time2 = timestamp_est)]
setkey(text_tidy_data_filtered, participant_id, time1,time2)
test <- foverlaps(daily_ema_data,text_tidy_data_filtered, by.x = c("participant_id","start_time_ema", "timestamp_ema"), nomatch = 0L)
what <- test %>%
group_by(participant_id,timestamp_ema) %>%
count(daily_sentiment=mean(sentiment))
library(dplyr)
hlm_data_sentiment <- merge(what, daily_ema_data, by=c("participant_id","timestamp_ema")) %>%
select(participant_id,date,daily_sentiment,n,daily,timestamp_ema)
daily.imeans <- plyr::ddply(hlm_data_sentiment, "participant_id", summarize, imean.n=mean(n, na.rm=TRUE),imean.daily_sentiment=mean(daily_sentiment, na.rm=TRUE),imean.daily=mean(daily, na.rm=TRUE))
daily.imeans$imean.n.c <- scale(daily.imeans$imean.n,center=TRUE,scale=FALSE)
daily.imeans$imean.daily.c <- scale(daily.imeans$imean.daily,center=TRUE,scale=FALSE)
hlm_data_sentiment <- merge(hlm_data_sentiment,daily.imeans,by=c("participant_id"))
hlm_data_sentiment$n.state <- hlm_data_sentiment$n - hlm_data_sentiment$imean.n
hlm_data_sentiment$daily.state <- hlm_data_sentiment$daily - hlm_data_sentiment$imean.daily
hlm_data_sentiment$n_zscore <- ave(hlm_data_sentiment$n.state, hlm_data_sentiment$participant_id, FUN=scale)
hlm_data_sentiment$n_zscore[hlm_data_sentiment$n_zscore=="NaN"] <- 0
hlm_data_sentiment <- hlm_data_sentiment %>%
group_by(participant_id) %>%
mutate(diff_days = difftime(date, min(date),units="days"))
# mean_data <- hlm_data_sentiment %>%
#   select(participant_id,imean.daily,imean.n) %>%
#   distinct(participant_id,imean.n,imean.daily)
#
# summary(lm(imean.daily ~ imean.n,mean_data))
fpp <- c("i","me","my","mine","im","myself","ikr","idgaf","ik")
#,"ourselves","we","us","our","ours"
text_tidy_data_filtered$fpp <- text_tidy_data_filtered$word %in% fpp
text_tidy_data_filtered$fpp <- as.factor(text_tidy_data_filtered$fpp)
text_tidy_data_filtered <- text_tidy_data_filtered %>%
mutate(word = str_replace(word, "ðÿ",""))
text_tidy_data_filtered$word[text_tidy_data_filtered$word==""] <- NA
text_tidy_data_filtered <- text_tidy_data_filtered %>%
drop_na(word)
text_tidy_data_filtered$social<- classify[text_tidy_data_filtered$app]
text_tidy_data_filtered$social <- as.factor(text_tidy_data_filtered$social)
hlm_data_sentiment$start_time_ema <- hlm_data_sentiment$timestamp_ema - hours(24)
setDT(text_tidy_data_filtered)
setDT(hlm_data_sentiment)
setDT(text_tidy_data_filtered)[, `:=`(
time1 = timestamp_est,
time2 = timestamp_est)]
setkey(text_tidy_data_filtered, participant_id, time1,time2)
test <- foverlaps(hlm_data_sentiment,text_tidy_data_filtered, by.x = c("participant_id","start_time_ema", "timestamp_ema"), nomatch = 0L)
what <- test %>%
group_by(participant_id, timestamp_ema,.drop=FALSE) %>%
count(fpp) %>%
filter(fpp == "TRUE") %>%
mutate(fpp_n = n) %>%
select(-n,-fpp)
daily_text_pronouns <- hlm_data_sentiment %>%
left_join(what,by = c("participant_id","timestamp_ema"))
bleh <- daily_text_pronouns %>%
select(participant_id,timestamp_ema,daily,fpp_n)
# daily_text_pronouns <- text_tidy_data_filtered %>%
#   count(participant_id, date, fpp) %>%
#   group_by(participant_id,date) %>%
#   mutate(fpp_proportion = n / sum(n)) %>%
#   filter(fpp == "TRUE") %>%
#   mutate(fpp_n = n) %>%
#   select(-n,-fpp)
#
# daily_text_pronouns <- hlm_data_sentiment %>%
#   left_join(daily_text_pronouns,by = c("participant_id","date"))
#daily_text_pronouns <- daily_text_pronouns %>%
# filter(fpp_n < 200)
# base_model <- lmer(daily ~ 1 + (1|participant_id),daily_text_pronouns)
#
# model_3_1 <- lmer(daily ~ fpp_proportion*daily_sentiment + (1|participant_id), daily_text_pronouns)
#
# summary(model_3_1)
#
# interact_plot(model_3_1, fpp_proportion,daily_sentiment)
daily.imeans <- plyr::ddply(daily_text_pronouns, c("participant_id"), summarize,imean.fpp_n=mean(fpp_n, na.rm=TRUE))
daily.imeans$imean.fpp_n.c <- scale(daily.imeans$imean.fpp_n,center=TRUE,scale=FALSE)
daily_text_pronouns <- merge(daily_text_pronouns,daily.imeans,by=c("participant_id"))
daily_text_pronouns$fpp_n.state <- daily_text_pronouns$fpp_n - daily_text_pronouns$imean.fpp_n
daily_text_pronouns$fpp_zscore <- ave(daily_text_pronouns$fpp_n.state, daily_text_pronouns$participant_id, FUN=scale)
daily_text_pronouns$fpp_zscore[daily_text_pronouns$fpp_zscore=="NaN"] <- 0
daily_text_pronouns$daily_zscore <- ave(daily_text_pronouns$daily.state, daily_text_pronouns$participant_id, FUN=scale)
#daily_text_pronouns <- daily_text_pronouns %>%
#  filter(fpp_n.state < 600)
# lg.fit.q4 <- lme(fixed= daily.state ~ fpp_n.state*imean.fpp_n.c,
#                  random= ~ 1 +diff_days |participant_id,
#                  correlation = corAR1(),
#                  data=daily_text_pronouns,
#                  control = ctrl,
#                  na.action=na.exclude)
#cor(test$imean.fpp_n,test$imean.daily)
hlm_data_sentiment$start_time_ema <- hlm_data_sentiment$timestamp_ema + hours(24)
setDT(text_tidy_data_filtered)
setDT(hlm_data_sentiment)
setDT(text_tidy_data_filtered)[, `:=`(
time1 = timestamp_est,
time2 = timestamp_est)]
setkey(text_tidy_data_filtered, participant_id, time1,time2)
test <- foverlaps(hlm_data_sentiment,text_tidy_data_filtered, by.x = c("participant_id", "timestamp_ema","start_time_ema"), nomatch = 0L)
what <- test %>%
group_by(participant_id, timestamp_ema,.drop=FALSE) %>%
count(fpp) %>%
filter(fpp == "TRUE") %>%
mutate(fpp_n = n) %>%
select(-n,-fpp)
daily_text_pronouns_post<- hlm_data_sentiment %>%
left_join(what,by = c("participant_id","timestamp_ema"))
daily_text_pronouns_post <- daily_text_pronouns_post %>%
drop_na(fpp_n)
daily.imeans <- plyr::ddply(daily_text_pronouns_post, c("participant_id"), summarize,imean.fpp_n=mean(fpp_n, na.rm=TRUE))
daily.imeans$imean.fpp_n.c <- scale(daily.imeans$imean.fpp_n,center=TRUE,scale=FALSE)
daily_text_pronouns_post <- merge(daily_text_pronouns_post,daily.imeans,by=c("participant_id"))
daily_text_pronouns_post$fpp_n.state <- daily_text_pronouns_post$fpp_n - daily_text_pronouns_post$imean.fpp_n
daily_text_pronouns_post$fpp_zscore <- ave(daily_text_pronouns_post$fpp_n.state, daily_text_pronouns_post$participant_id, FUN=scale)
daily_text_pronouns_post$fpp_zscore[daily_text_pronouns_post$fpp_zscore=="NaN"] <- 0
daily_text_pronouns_post$daily_zscore <- ave(daily_text_pronouns_post$daily.state, daily_text_pronouns_post$participant_id, FUN=scale)
model_post_base <- lmer(n ~ 1 + (1|participant_id), daily_text_pronouns_post,REML=FALSE)
summary(model_post_base)
model_post <- lmer(n_zscore ~ daily_zscore + diff_days + (1|participant_id), daily_text_pronouns_post,REML=FALSE)
summary(model_post)
tab_model(model_post_base,model_post)
library(sjPlot)
model_base <- lmer(daily ~ 1 + (1|participant_id),data=daily_text_pronouns)
model_n <- lmer(daily ~  n_zscore*imean.n.c + (1|participant_id), data=daily_text_pronouns)
anova(model_base,model_n)
tab_model(model_n,show.std=TRUE,pred.labels = c("(Intercept)","Word Count(n)"),dv.labels=("Daily Mood Score"),show.r2=FALSE)
plot_model(model_n,type="int")
interact_plot(model_n,imean.n.c,n_zscore,interval=TRUE,plot.points=TRUE)
daily_text_pronouns %>%
select(participant_id,imean.daily,imean.daily_sentiment) %>%
distinct(participant_id,imean.daily_sentiment,imean.daily) %>%
ggplot(aes(x = imean.daily_sentiment, y = imean.daily)) +
geom_point() +
stat_smooth(method = "lm", col = "red") +
xlab("Mean Daily FPP Use") +
ylab("Mean Daily Mood Score") +
apatheme
# text_tidy_sentiment <- text_tidy_data_filtered %>%
#   distinct(participant_id,date,timestamp_est,sentiment)
#
#
# daily_text_sentiment <- text_tidy_sentiment %>%
#    group_by(participant_id, date) %>%
#    mutate(daily_sentiment = mean(sentiment)) %>%
#    distinct(participant_id,date,.keep_all = TRUE)
#
daily_text_pronouns <- daily_text_pronouns %>%
select(-imean.daily_sentiment)
#hlm_sentiment <- merge(daily_text_sentiment, daily_ema_data, by=c("participant_id","date")) %>%
#  select(participant_id,date,daily_sentiment,daily)
daily.imeans <- plyr::ddply(daily_text_pronouns, c("participant_id"), summarize,imean.daily_sentiment=mean(daily_sentiment, na.rm=TRUE))
daily.imeans$imean.daily_sentiment.c <- scale(daily.imeans$imean.daily_sentiment,center=TRUE,scale=FALSE)
daily_text_pronouns <- merge(daily_text_pronouns,daily.imeans,by=c("participant_id"))
daily_text_pronouns$daily_sentiment.state <- daily_text_pronouns$daily_sentiment - daily_text_pronouns$imean.daily_sentiment
daily_text_pronouns$daily_sentiment_zscore <- ave(daily_text_pronouns$daily_sentiment.state, daily_text_pronouns$participant_id, FUN=scale)
daily_text_pronouns$daily_sentiment_zscore[daily_text_pronouns$daily_sentiment_zscore=="NaN"] <- 0
daily_text_pronouns$participant_id <- as.factor(daily_text_pronouns$participant_id)
daily_text_pronouns$daily_zscore <- ave(daily_text_pronouns$daily.state, daily_text_pronouns$participant_id, FUN=scale)
daily_text_pronouns <- daily_text_pronouns %>%
drop_na(fpp_zscore)
model_base <- lmer(daily ~ 1 + (1|participant_id),daily_text_pronouns)
model_sentiment_base <- lmer(daily ~ 1 + (1|participant_id),daily_text_pronouns)
model_sentiment <- lmer(daily ~ daily_sentiment_zscore*n_zscore*fpp_zscore + (1|participant_id),daily_text_pronouns)
anova(model_base,model_sentiment_base,model_sentiment)
plot_model(model_sentiment,type="int")
tab_model(model_sentiment,show.std=TRUE,pred.labels = c("(Intercept)","Daily Sentiment"),dv.labels=("Daily Mood Score"),show.r2=FALSE)
library(ggiraph)
library(ggiraphExtra)
library(plyr)
maybe <- ggeffects::ggpredict(model_sentiment,terms=c("daily_sentiment_zscore","imean.daily_sentiment"))
